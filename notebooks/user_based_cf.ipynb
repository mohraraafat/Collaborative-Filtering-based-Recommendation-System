{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "909ba5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25746698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_loader import load_data\n",
    "from src.recommender import build_dataset, user_based_cf, get_top_n_recommendations, save_recommendations\n",
    "from src.evaluation import evaluate_and_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f513f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings, _, _ = load_data(r'C:\\Users\\mohr\\Desktop\\task2305305\\data')\n",
    "ratings.drop_duplicates(subset=['user_id', 'item_id'], keep='last', inplace=True)\n",
    "ratings.dropna(subset=['user_id', 'item_id', 'rating'], inplace=True)\n",
    "ratings['user_id'] = pd.to_numeric(ratings['user_id'], errors='coerce')\n",
    "ratings['item_id'] = pd.to_numeric(ratings['item_id'], errors='coerce')\n",
    "ratings['rating'] = pd.to_numeric(ratings['rating'], errors='coerce')\n",
    "ratings.dropna(subset=['user_id', 'item_id', 'rating'], inplace=True)\n",
    "ratings = ratings[(ratings['rating'] >= 1) & (ratings['rating'] <= 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b35c011",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = build_dataset(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c43e71cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "algo, predictions = user_based_cf(data, sim_name='cosine', k=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9342a4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Evaluation Metrics:\n",
      "RMSE: 1.0223\n",
      "ðŸ“Œ Average Precision@10: 0.7238\n",
      "ðŸ“Œ Average Recall@10: 0.5388\n",
      "ðŸ“ Metrics saved to: results/user_based_evaluation.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RMSE': 1.022276156768975,\n",
       " 'Precision@10': 0.7237977410829995,\n",
       " 'Recall@10': 0.5387519964822798}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_and_report(predictions, k=10, save_path=\"results/user_based_evaluation.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b016544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = get_top_n_recommendations(predictions, n=10)\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "save_recommendations(top_n, \"results/user_based_recommendations.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
